{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clustering學習筆記.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5KhE8YWeQYn1bH6KdJ+4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emily2925/machine_learning_algorithm/blob/main/Clustering%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering演算法概要**\n",
        "**軟分群：不一定會所有點都分群(待研究)**\n",
        "\n",
        "**硬分群：所有點都會分群**\n",
        "\n",
        "\n",
        "\n",
        "*   切割式分群：K系列\n",
        "*   階層式分群：Hierarchy系列，相較於純分群可以看出兩倆關係和形成群集的順序，例如基因分群\n",
        "\n",
        "\n",
        ">**使用場景**\n",
        "* 純數值變數：KMeans, Hierarchy\n",
        "* 純類別變數：KModes, Gower matrix + Hierarchy\n",
        "* 數值＋類別變數：KPrototypes, Gower matrix + Hierarchy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S0EH3H7uKo8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**此筆記整理Kmeans,Kmodes,KPrototypes,Hierarchy之原理、使用場合、限制、前置作業、實作程式和結果解釋**<br>\n",
        "*   Kmeans原理主要參考：https://www.youtube.com/watch?v=4b5d3muPQmA&ab_channel=StatQuestwithJoshStarmer\n",
        "*   KModes原理主要參考：https://www.youtube.com/watch?v=b39_vipRkUo&ab_channel=AysanFernandes\n",
        "*   KModes參考程式：https://www.analyticsvidhya.com/blog/2021/06/kmodes-clustering-algorithm-for-categorical-data/\n",
        "*   KPrototypes原理主要參考：https://www.hindawi.com/journals/mpe/2020/5143797/\n",
        "*   KMeans、KModes、KPrototype計算方式比較：https://www.jianshu.com/p/c9dcc52b85d4\n",
        "*   KModes和KPrototype都可以用kmodes套件取用：https://pypi.org/project/kmodes/\n",
        "*   Hierarchy原理主要參考：https://www.youtube.com/watch?v=7xHsRkOdVwo&ab_channel=StatQuestwithJoshStarmer\n",
        "*   Hierarchy如用於mixed data要先用gower distance(1)：https://towardsdatascience.com/clustering-on-numerical-and-categorical-features-6e0ebcf1cbad\n",
        "*   Hierarchy如用於mixed data要先用gower distance(2)：https://www.thinkdatascience.com/post/2019-12-16-introducing-python-package-gower/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gbsbcnDTq5CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pNX5lksHMaPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kmeans**"
      ],
      "metadata": {
        "id": "oV7z0m48vxB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.原理** <br>\n",
        "a. 先決定要k個群，n次嘗試(即n_init，預設10)，並隨意選定k個樣本點作為centroids<br>\n",
        "b. 計算其他樣本點和這些centroids的距離(歐幾里德，平方加總開根號，variation, MSE)，和誰最接近則被分入該群<br>\n",
        "c. 分完後將目前k個群集的平均值點作為k個新的centroids，並重複b和c步驟，直到cluster沒有變化<br>\n",
        "d. 完成第一次的嘗試，並將各樣本點和最終該群的centroids之間的距離加總作為評估值\n",
        "e. 重複a到d，但改變起始樣本點，直到做了共n次嘗試，將n次中，variation最小的嘗試作為k群n次的評估值\n",
        "\n",
        "**2.使用場合** <br>\n",
        "對於一群不明特質的群體希望進行分類<br>\n",
        "a.希望對一群客戶精準行銷：用消費習慣、使用裝置分群<br>\n",
        "b.金融詐騙樣態分群<br>\n",
        "c.圖像<br>\n",
        "d.文本<br>\n",
        "\n",
        "**3.限制** <br>\n",
        "a. 不能是類別變數或dummy variable，因其數值大小無意義，故數值距離沒有意義=>可用KModes取代，如為混合資料則可用KPrototypes<br>\n",
        "b. 可能被離群值影響結果=>檢查、剔除看看結果差異<br>\n",
        "c. 有些資料分佈分群結果不佳，特殊形狀或uniform=>可看各群各值均值或改用hierarchy<br>\n",
        "\n",
        "**4.前置作業** <br>\n",
        "a. (必做)Normalization：因為各feature的值大小可能因單位或其他因素差很多，為了不讓數值變異本就超大的feature被重點呈現，需要標準化，可除以std，讓標準差=1<br>\n",
        "b. (必做)決定Seed：隨機選取初始值的方式一樣，可重現結果<br>\n",
        "c. (必做)決定k值：是先跑出各k值的variation加總結果，找出elbow point，即variation下降最多的點<br>\n",
        "b. (必做)檢查離群值<br>\n",
        "d. (Optional)Feature Selection：先評估一下要放入的feature或用其他演算法輔助<br>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aevjOa5Pv6sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 套件\n",
        "from numpy import random\n",
        "from scipy.cluster.vq import whiten\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 標準化 \n",
        "df['scaled_x'] = whiten(df['x'])\n",
        "df['scaled_y'] = whiten(df['y'])\n",
        "df_dum_detail = df[['scaled_x', 'scaled_y']]\n",
        "\n",
        "# 定好seed\n",
        "random.seed(12)"
      ],
      "metadata": {
        "id": "WRmyWFubv5ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 篩選k值：偵測現有下，k值應多少為最佳\n",
        "sse = []\n",
        "for k in range(1, 8):\n",
        "  print(k)\n",
        "  kmeans = KMeans(n_clusters=k)\n",
        "  kmeans.fit(df_dum_detail)\n",
        "  sse.append(kmeans.inertia_)\n",
        "\n",
        "# k值篩選：圖像化篩選結果，SSE肘點為選擇點\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "plt.plot(range(1, 8), sse)\n",
        "plt.xticks(range(1, 8))\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"SSE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KVuEffc8vuXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 分組\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "labels = kmeans.fit_predict(df_dum_detail)\n",
        "# 將分組資料 (分類標籤) 併入原資料\n",
        "lb = pd.DataFrame(labels, columns=['labels'])\n",
        "df_result = pd.concat((lb, df_dum_detail), axis=1)\n",
        "\n",
        "# 商品類別分類的結果-每組數量\n",
        "print(df_result.groupby(\"labels\").count())\n",
        "\n",
        "# 商品類別分類的結果-平均值\n",
        "print(df_result.groupby(\"labels\").mean())\n",
        "\n",
        "# 圖像化結果\n",
        "df_result.groupby('labels')[scaled_features].mean().plot(legend=True, kind='bar')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M1Vt5H9UTcKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KModes**"
      ],
      "metadata": {
        "id": "GdjKbU3q56ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**整個過程、原理和KMeans幾乎一樣，只是算距離的方式有些不同，是用海明威距離，且不需事前先Normalization，以下說明計算距離的概念**<br>\n",
        "\n",
        "a. 隨機選3點(假設k=3)作為Centroids<br>\n",
        "b. 將每個點去和Centroids比較，例如先和C1比，比較時去看每個類別只要有不同即+1，則和C1的距離及加總，然後算C2距離、C3距離<br>\n",
        "c. 每個點會被分類到和C距離最小的類別<br>\n",
        "d. 接著重選新Centroids，選擇方式是把該Cluster所有點的每個feature值攤開看，每個feature都選目前最多點有的值，即產生Centroids<br>\n",
        "e. 一直做到Cluster不變動<br>"
      ],
      "metadata": {
        "id": "PYxD9mCl6CsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 套件\n",
        "from numpy import random\n",
        "from kmodes.kmodes import KModes\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 定好seed\n",
        "random.seed(12)"
      ],
      "metadata": {
        "id": "pL6aWl36UTcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 篩選k值\n",
        "cost = []\n",
        "K = range(1,5)\n",
        "for num_clusters in list(K):\n",
        "    kmode = KModes(n_clusters=num_clusters, init = \"random\", n_init = 5, verbose=1)\n",
        "    kmode.fit_predict(df_dum_detail)\n",
        "    cost.append(kmode.cost_)\n",
        "\n",
        "plt.plot(K, cost, 'bx-')\n",
        "plt.xlabel('No. of clusters')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jcRo75o_V8-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model with clusters\n",
        "kmode = KModes(n_clusters=2, init = \"random\", n_init = 5, verbose=1)\n",
        "clusters = kmode.fit_predict(df_dum_detail)\n",
        "df_dum_detail.insert(0, \"Cluster\", clusters, True)"
      ],
      "metadata": {
        "id": "uUoLVSu5V9Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dum_detail.groupby('Cluster')['is_cart'].count()\n",
        "df_dum_detail.groupby(['Cluster', 'is_cart']).count()"
      ],
      "metadata": {
        "id": "LkLEBfg9V9C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KPrototypes**"
      ],
      "metadata": {
        "id": "I2prB3JU7Nhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**整個過程、原理和KMeans幾乎一樣，算距離的方式為數值變數用歐幾里德距離算，然後類別變數用KModes的方式算**<br>"
      ],
      "metadata": {
        "id": "lxFC-qNo7WF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 套件\n",
        "from numpy import random\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 定好seed\n",
        "random.seed(12)"
      ],
      "metadata": {
        "id": "wTC7dof5V9Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 篩選k值\n",
        "cost = []\n",
        "K = range(1,5)\n",
        "for num_clusters in list(K):\n",
        "    kprototypes = KPrototypes(n_clusters=num_clusters, init = \"random\", n_init = 5, verbose=1)\n",
        "    kprototypes.fit_predict(df_dum_detail)\n",
        "    cost.append(kprototypes.cost_)\n",
        "\n",
        "plt.plot(K, cost, 'bx-')\n",
        "plt.xlabel('No. of clusters')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cWfiGl-e_I1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model with clusters\n",
        "kprototypes = KPrototypes(n_clusters=2, init = \"random\", n_init = 5, verbose=1)\n",
        "clusters = kprototypes.fit_predict(df_dum_detail)\n",
        "df_dum_detail.insert(0, \"Cluster\", clusters, True)"
      ],
      "metadata": {
        "id": "uglLjX6HV9Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dum_detail.groupby('Cluster')['is_cart'].count()\n",
        "df_dum_detail.groupby(['Cluster', 'is_cart']).count()"
      ],
      "metadata": {
        "id": "w_UUgpSiUTeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchy**"
      ],
      "metadata": {
        "id": "eKSJsk6bIGf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.原理** <br>\n",
        "a. 兩兩比較樣本點，用歐幾里得距離(多種選擇)，距離最近的併成一cluster<br>\n",
        "b. 一樣兩兩比較，cluster和cluster間的距離比較方式也有多種，例如比較最近的點或最遠的點<br>\n",
        "c. 最終併成一個群，但整個過程和每個群行成的距離、順序都可繪出<br>\n",
        "\n",
        "**2.使用場合** <br>\n",
        "對於一群不明特質的群體進行分類，且希望知道群的形成順序和關係演進，奇怪的資料分佈也可用<br>\n",
        "a. 基因分群<br>\n",
        "\n",
        "**3.限制** <br>\n",
        "a. 距離計算和比較cluster方法改變，結果差很多=>無結論，選用有insight的方法<br>\n",
        "\n",
        "**4.前置作業** <br>\n",
        "a. (必做)Normalization：數值變數要做<br>\n",
        "b. (Optional)Gower Matrix：混合變數要做這個<br>\n",
        "d. (Optional)Feature Selection：先評估一下要放入的feature或用其他演算法輔助<br>"
      ],
      "metadata": {
        "id": "JyID7-z2Q7F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gower\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram"
      ],
      "metadata": {
        "id": "DXsGixMEHeGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 算出來所有狀況連一連的數字，並畫圖，看一看決定想分幾群\n",
        "# 數值變數先標準化 參考Kmeans區\n",
        "dm = gower.gower_matrix(df) # 非混合變數本步驟不需要\n",
        "Zd = linkage(dm)\n",
        "dendrogram(Zd) "
      ],
      "metadata": {
        "id": "ilsqlEuIHeEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 想好群數下labels\n",
        "labels = fcluster(Zd, 3, criterion='maxclust')\n",
        "df.insert(0, \"Cluster\", labels, True)"
      ],
      "metadata": {
        "id": "AkhFCUjhHeCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dum_detail.groupby('Cluster')['is_cart'].count()\n",
        "df_dum_detail.groupby(['Cluster', 'is_cart']).count()"
      ],
      "metadata": {
        "id": "0dE_sSAjHeAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xMxqJRkuHd-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}